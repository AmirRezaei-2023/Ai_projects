{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "d333515a",
      "metadata": {
        "id": "d333515a"
      },
      "source": [
        "<h1 align=center style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
        "<font face=\"vazir\" color=\"#0099cc\">\n",
        "Perceptron\n",
        "</font>\n",
        "</h1>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c5af1784",
      "metadata": {
        "id": "c5af1784"
      },
      "source": [
        "<h2 align=right style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
        "<font face=\"vazir\" color=\"#0099cc\">\n",
        "</font>\n",
        "</h2>\n",
        "\n",
        "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
        "<font face=\"vazir\" size=3>\n",
        "Importing the libraries\n",
        "</font>\n",
        "</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "99450f9e",
      "metadata": {
        "id": "99450f9e"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score\n",
        "from inspect import getsource"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7dcb9e87",
      "metadata": {
        "id": "7dcb9e87",
        "outputId": "3cf0dd6f-d07f-41a2-f666-f8e495856d8c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SepalLengthCm</th>\n",
              "      <th>SepalWidthCm</th>\n",
              "      <th>PetalLengthCm</th>\n",
              "      <th>PetalWidthCm</th>\n",
              "      <th>Species</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm      Species\n",
              "0            5.1           3.5            1.4           0.2  Iris-setosa\n",
              "1            4.9           3.0            1.4           0.2  Iris-setosa\n",
              "2            4.7           3.2            1.3           0.2  Iris-setosa\n",
              "3            4.6           3.1            1.5           0.2  Iris-setosa\n",
              "4            5.0           3.6            1.4           0.2  Iris-setosa"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data = pd.read_csv('../data/iris.csv')\n",
        "train_data.drop(columns=['Id'], inplace=True)\n",
        "train_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1617a7d7",
      "metadata": {
        "id": "1617a7d7",
        "outputId": "97232a4c-c5af-4e52-9624-2d7a8b80f0b5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['Iris-setosa', 'Iris-versicolor', 'Iris-virginica'], dtype=object)"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data['Species'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f7c23000",
      "metadata": {
        "id": "f7c23000"
      },
      "outputs": [],
      "source": [
        "df1 = train_data.drop(train_data.index[train_data['Species'] == 'Iris-virginica'])\n",
        "df1.reset_index(inplace=True, drop=True)\n",
        "\n",
        "df2 = train_data.drop(train_data.index[train_data['Species'] == 'Iris-versicolor'])\n",
        "df2.reset_index(inplace=True, drop=True)\n",
        "\n",
        "df3 = train_data.drop(train_data.index[train_data['Species'] == 'Iris-setosa'])\n",
        "df3.reset_index(inplace=True, drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "704751ee",
      "metadata": {
        "id": "704751ee"
      },
      "outputs": [],
      "source": [
        "df1.to_csv('df1.csv', index=False)\n",
        "df2.to_csv('df2.csv', index=False)\n",
        "df3.to_csv('df3.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f493320e",
      "metadata": {
        "id": "f493320e"
      },
      "outputs": [],
      "source": [
        "df1['Species'].replace(to_replace=['Iris-setosa', 'Iris-versicolor'], value=[1., -1.], inplace=True)\n",
        "\n",
        "df2['Species'].replace(to_replace=['Iris-setosa', 'Iris-virginica'], value=[1., -1.], inplace=True)\n",
        "\n",
        "df3['Species'].replace(to_replace=['Iris-versicolor', 'Iris-virginica'], value=[1., -1.], inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a1a8f40d",
      "metadata": {
        "id": "a1a8f40d"
      },
      "outputs": [],
      "source": [
        "# Splitting the label and features columns\n",
        "df1_y = df1['Species']\n",
        "df1_X = df1.drop(columns='Species')\n",
        "\n",
        "df2_y = df2['Species']\n",
        "df2_X = df2.drop(columns='Species')\n",
        "\n",
        "df3_y = df3['Species']\n",
        "df3_X = df3.drop(columns='Species')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e43535d",
      "metadata": {
        "id": "0e43535d"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "sc1 = MinMaxScaler()\n",
        "df1_X_scaled = sc1.fit_transform(df1_X)\n",
        "\n",
        "sc2 = MinMaxScaler()\n",
        "df2_X_scaled = sc2.fit_transform(df2_X)\n",
        "\n",
        "sc3 = MinMaxScaler()\n",
        "df3_X_scaled = sc3.fit_transform(df3_X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "231cd2b5",
      "metadata": {
        "id": "231cd2b5"
      },
      "outputs": [],
      "source": [
        "class Perceptron:\n",
        "\n",
        "    def __init__(self):\n",
        "        self.weights = None\n",
        "\n",
        "    def weighting(self, input):\n",
        "        return np.dot(input, self.weights)\n",
        "\n",
        "    def activation(self, weighted_input):\n",
        "\n",
        "        # sign activation function\n",
        "        if weighted_input >= 0:\n",
        "            return 1\n",
        "        else:\n",
        "            return -1\n",
        "\n",
        "    def predict(self, inputs):\n",
        "\n",
        "        # adding a 1 to the first position of each input (adding the bias term)\n",
        "        new_inputs = np.insert(inputs, 0, [1], axis=1)\n",
        "\n",
        "        # a list of final prediction for each test sample\n",
        "        predictions = []\n",
        "\n",
        "        for input in new_inputs:\n",
        "\n",
        "            weighted_input = self.weighting(input)\n",
        "            prediction = self.activation(weighted_input)\n",
        "            predictions.append(prediction)\n",
        "\n",
        "        # converting the list to a numpy array\n",
        "        predictions = np.array(predictions)\n",
        "\n",
        "        return predictions\n",
        "\n",
        "    def fit(self, inputs, outputs, learning_rate=0.1, epochs=64):\n",
        "\n",
        "        # adding a 1 to the first position of each input (adding the bias term)\n",
        "        new_inputs = np.insert(inputs, 0, [1], axis=1)\n",
        "\n",
        "        # initializing the weights\n",
        "        self.weights = np.random.rand(new_inputs.shape[1])\n",
        "\n",
        "        # training loop\n",
        "        for epoch in range(epochs):\n",
        "            for sample, target in zip(new_inputs, outputs):\n",
        "                weighted_input = self.weighting(sample)\n",
        "                diff =  target - self.activation(weighted_input)\n",
        "                self.weights = self.weights + learning_rate * diff * sample\n",
        "\n",
        "            print('Epoch #' + str(epoch) + ' - Accuracy: ' + str(accuracy_score(self.predict(inputs), outputs)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d4f7297d",
      "metadata": {
        "id": "d4f7297d",
        "outputId": "01798179-b9d4-4978-d414-edf14d0c05af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch #0 - Accuracy: 0.31\n",
            "Epoch #1 - Accuracy: 0.5\n",
            "Epoch #2 - Accuracy: 0.56\n",
            "Epoch #3 - Accuracy: 0.8\n",
            "Epoch #4 - Accuracy: 0.99\n",
            "Epoch #5 - Accuracy: 1.0\n",
            "Epoch #6 - Accuracy: 1.0\n",
            "Epoch #7 - Accuracy: 1.0\n",
            "Epoch #8 - Accuracy: 1.0\n",
            "Epoch #9 - Accuracy: 1.0\n",
            "Epoch #10 - Accuracy: 1.0\n",
            "Epoch #11 - Accuracy: 1.0\n",
            "Epoch #12 - Accuracy: 1.0\n",
            "Epoch #13 - Accuracy: 1.0\n",
            "Epoch #14 - Accuracy: 1.0\n",
            "Epoch #15 - Accuracy: 1.0\n",
            "Epoch #16 - Accuracy: 1.0\n",
            "Epoch #17 - Accuracy: 1.0\n",
            "Epoch #18 - Accuracy: 1.0\n",
            "Epoch #19 - Accuracy: 1.0\n",
            "Epoch #20 - Accuracy: 1.0\n",
            "Epoch #21 - Accuracy: 1.0\n",
            "Epoch #22 - Accuracy: 1.0\n",
            "Epoch #23 - Accuracy: 1.0\n",
            "Epoch #24 - Accuracy: 1.0\n",
            "Epoch #25 - Accuracy: 1.0\n",
            "Epoch #26 - Accuracy: 1.0\n",
            "Epoch #27 - Accuracy: 1.0\n",
            "Epoch #28 - Accuracy: 1.0\n",
            "Epoch #29 - Accuracy: 1.0\n",
            "Epoch #30 - Accuracy: 1.0\n",
            "Epoch #31 - Accuracy: 1.0\n"
          ]
        }
      ],
      "source": [
        "perceptron = Perceptron()\n",
        "perceptron.fit(df1_X_scaled, df1_y, learning_rate=0.01, epochs=32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e48be138",
      "metadata": {
        "id": "e48be138",
        "outputId": "e199f0df-f285-4175-e72d-52e5a8ee041a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch #0 - Accuracy: 0.45\n",
            "Epoch #1 - Accuracy: 0.54\n",
            "Epoch #2 - Accuracy: 0.71\n",
            "Epoch #3 - Accuracy: 0.86\n",
            "Epoch #4 - Accuracy: 0.92\n",
            "Epoch #5 - Accuracy: 0.96\n",
            "Epoch #6 - Accuracy: 0.99\n",
            "Epoch #7 - Accuracy: 0.99\n",
            "Epoch #8 - Accuracy: 0.99\n",
            "Epoch #9 - Accuracy: 0.99\n",
            "Epoch #10 - Accuracy: 0.99\n",
            "Epoch #11 - Accuracy: 0.99\n",
            "Epoch #12 - Accuracy: 0.99\n",
            "Epoch #13 - Accuracy: 0.99\n",
            "Epoch #14 - Accuracy: 0.99\n",
            "Epoch #15 - Accuracy: 0.99\n",
            "Epoch #16 - Accuracy: 0.99\n",
            "Epoch #17 - Accuracy: 0.99\n",
            "Epoch #18 - Accuracy: 0.99\n",
            "Epoch #19 - Accuracy: 0.99\n",
            "Epoch #20 - Accuracy: 0.99\n",
            "Epoch #21 - Accuracy: 0.99\n",
            "Epoch #22 - Accuracy: 1.0\n",
            "Epoch #23 - Accuracy: 1.0\n",
            "Epoch #24 - Accuracy: 1.0\n",
            "Epoch #25 - Accuracy: 1.0\n",
            "Epoch #26 - Accuracy: 1.0\n",
            "Epoch #27 - Accuracy: 1.0\n",
            "Epoch #28 - Accuracy: 1.0\n",
            "Epoch #29 - Accuracy: 1.0\n",
            "Epoch #30 - Accuracy: 1.0\n",
            "Epoch #31 - Accuracy: 1.0\n"
          ]
        }
      ],
      "source": [
        "perceptron = Perceptron()\n",
        "perceptron.fit(df2_X_scaled, df2_y, learning_rate=0.01, epochs=32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e1c9f67",
      "metadata": {
        "id": "3e1c9f67",
        "outputId": "674e10b3-3430-4b7f-ef3e-eb8f15828f4d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch #0 - Accuracy: 0.5\n",
            "Epoch #1 - Accuracy: 0.5\n",
            "Epoch #2 - Accuracy: 0.5\n",
            "Epoch #3 - Accuracy: 0.5\n",
            "Epoch #4 - Accuracy: 0.5\n",
            "Epoch #5 - Accuracy: 0.69\n",
            "Epoch #6 - Accuracy: 0.89\n",
            "Epoch #7 - Accuracy: 0.75\n",
            "Epoch #8 - Accuracy: 0.93\n",
            "Epoch #9 - Accuracy: 0.88\n",
            "Epoch #10 - Accuracy: 0.74\n",
            "Epoch #11 - Accuracy: 0.75\n",
            "Epoch #12 - Accuracy: 0.71\n",
            "Epoch #13 - Accuracy: 0.94\n",
            "Epoch #14 - Accuracy: 0.95\n",
            "Epoch #15 - Accuracy: 0.95\n",
            "Epoch #16 - Accuracy: 0.93\n",
            "Epoch #17 - Accuracy: 0.86\n",
            "Epoch #18 - Accuracy: 0.8\n",
            "Epoch #19 - Accuracy: 0.95\n",
            "Epoch #20 - Accuracy: 0.78\n",
            "Epoch #21 - Accuracy: 0.79\n",
            "Epoch #22 - Accuracy: 0.95\n",
            "Epoch #23 - Accuracy: 0.95\n",
            "Epoch #24 - Accuracy: 0.95\n",
            "Epoch #25 - Accuracy: 0.95\n",
            "Epoch #26 - Accuracy: 0.94\n",
            "Epoch #27 - Accuracy: 0.86\n",
            "Epoch #28 - Accuracy: 0.84\n",
            "Epoch #29 - Accuracy: 0.84\n",
            "Epoch #30 - Accuracy: 0.86\n",
            "Epoch #31 - Accuracy: 0.85\n",
            "Epoch #32 - Accuracy: 0.84\n",
            "Epoch #33 - Accuracy: 0.95\n",
            "Epoch #34 - Accuracy: 0.95\n",
            "Epoch #35 - Accuracy: 0.95\n",
            "Epoch #36 - Accuracy: 0.95\n",
            "Epoch #37 - Accuracy: 0.95\n",
            "Epoch #38 - Accuracy: 0.95\n",
            "Epoch #39 - Accuracy: 0.95\n",
            "Epoch #40 - Accuracy: 0.95\n",
            "Epoch #41 - Accuracy: 0.88\n",
            "Epoch #42 - Accuracy: 0.89\n",
            "Epoch #43 - Accuracy: 0.9\n",
            "Epoch #44 - Accuracy: 0.92\n",
            "Epoch #45 - Accuracy: 0.94\n",
            "Epoch #46 - Accuracy: 0.91\n",
            "Epoch #47 - Accuracy: 0.94\n",
            "Epoch #48 - Accuracy: 0.94\n",
            "Epoch #49 - Accuracy: 0.93\n",
            "Epoch #50 - Accuracy: 0.94\n",
            "Epoch #51 - Accuracy: 0.88\n",
            "Epoch #52 - Accuracy: 0.9\n",
            "Epoch #53 - Accuracy: 0.95\n",
            "Epoch #54 - Accuracy: 0.95\n",
            "Epoch #55 - Accuracy: 0.95\n",
            "Epoch #56 - Accuracy: 0.95\n",
            "Epoch #57 - Accuracy: 0.94\n",
            "Epoch #58 - Accuracy: 0.95\n",
            "Epoch #59 - Accuracy: 0.94\n",
            "Epoch #60 - Accuracy: 0.94\n",
            "Epoch #61 - Accuracy: 0.94\n",
            "Epoch #62 - Accuracy: 0.91\n",
            "Epoch #63 - Accuracy: 0.9\n"
          ]
        }
      ],
      "source": [
        "perceptron = Perceptron()\n",
        "perceptron.fit(df3_X_scaled, df3_y, learning_rate=0.01, epochs=64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f9c9053d",
      "metadata": {
        "id": "f9c9053d"
      },
      "outputs": [],
      "source": [
        "linearly_separable = [1, 2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c7961eff",
      "metadata": {
        "id": "c7961eff"
      },
      "outputs": [],
      "source": [
        "class Adaline:\n",
        "\n",
        "    def __init__(self):\n",
        "        self.weights = None\n",
        "\n",
        "    def weighting(self, input):\n",
        "        return np.dot(input, self.weights)\n",
        "\n",
        "    def activation(self, weighted_input):\n",
        "        return weighted_input\n",
        "\n",
        "    def predict(self, inputs):\n",
        "\n",
        "        # adding a 1 to the first position of each input (adding the bias term)\n",
        "        new_inputs = np.insert(inputs, 0, [1], axis=1)\n",
        "\n",
        "        # a list of final prediction for each test sample\n",
        "        predictions = []\n",
        "\n",
        "        for input in new_inputs:\n",
        "            weighted_input = self.weighting(input)\n",
        "            weighted_input = self.activation(weighted_input)\n",
        "            prediction = None\n",
        "            if weighted_input >= 0:\n",
        "                prediction = 1\n",
        "            else:\n",
        "                prediction = -1\n",
        "            predictions.append(prediction)\n",
        "\n",
        "        # converting the list to a numpy array\n",
        "        predictions = np.array(predictions)\n",
        "\n",
        "        return predictions\n",
        "\n",
        "    def fit(self, inputs, outputs, learning_rate=0.1, epochs=64):\n",
        "\n",
        "        # adding a 1 to the first position of each input (adding the bias term)\n",
        "        new_inputs = np.insert(inputs, 0, [1], axis=1)\n",
        "\n",
        "        # initializing the weights\n",
        "        self.weights = np.random.rand(new_inputs.shape[1])\n",
        "\n",
        "        # training loop\n",
        "        for epoch in range(epochs):\n",
        "            weighted_input = self.weighting(new_inputs)\n",
        "            diff =  outputs - self.activation(weighted_input)\n",
        "            self.weights = self.weights + learning_rate * new_inputs.T.dot(diff)\n",
        "\n",
        "            print('Epoch #' + str(epoch) + ' - Accuracy: ' + str(accuracy_score(self.predict(inputs), outputs)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "008fcefd",
      "metadata": {
        "id": "008fcefd",
        "outputId": "e66d93c9-406b-400e-d7a7-639fbe619fcf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch #0 - Accuracy: 0.5\n",
            "Epoch #1 - Accuracy: 0.5\n",
            "Epoch #2 - Accuracy: 0.5\n",
            "Epoch #3 - Accuracy: 0.5\n",
            "Epoch #4 - Accuracy: 0.62\n",
            "Epoch #5 - Accuracy: 0.66\n",
            "Epoch #6 - Accuracy: 1.0\n",
            "Epoch #7 - Accuracy: 0.96\n",
            "Epoch #8 - Accuracy: 1.0\n",
            "Epoch #9 - Accuracy: 1.0\n",
            "Epoch #10 - Accuracy: 1.0\n",
            "Epoch #11 - Accuracy: 1.0\n",
            "Epoch #12 - Accuracy: 1.0\n",
            "Epoch #13 - Accuracy: 1.0\n",
            "Epoch #14 - Accuracy: 1.0\n",
            "Epoch #15 - Accuracy: 1.0\n",
            "Epoch #16 - Accuracy: 1.0\n",
            "Epoch #17 - Accuracy: 1.0\n",
            "Epoch #18 - Accuracy: 1.0\n",
            "Epoch #19 - Accuracy: 1.0\n",
            "Epoch #20 - Accuracy: 1.0\n",
            "Epoch #21 - Accuracy: 1.0\n",
            "Epoch #22 - Accuracy: 1.0\n",
            "Epoch #23 - Accuracy: 1.0\n",
            "Epoch #24 - Accuracy: 1.0\n",
            "Epoch #25 - Accuracy: 1.0\n",
            "Epoch #26 - Accuracy: 1.0\n",
            "Epoch #27 - Accuracy: 1.0\n",
            "Epoch #28 - Accuracy: 1.0\n",
            "Epoch #29 - Accuracy: 1.0\n",
            "Epoch #30 - Accuracy: 1.0\n",
            "Epoch #31 - Accuracy: 1.0\n"
          ]
        }
      ],
      "source": [
        "adaline = Adaline()\n",
        "adaline.fit(df1_X_scaled, df1_y, learning_rate=0.01, epochs=32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "75920d3c",
      "metadata": {
        "id": "75920d3c",
        "outputId": "dd3be9fe-ae8d-4833-fc88-687197b8c67e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch #0 - Accuracy: 0.5\n",
            "Epoch #1 - Accuracy: 0.5\n",
            "Epoch #2 - Accuracy: 0.5\n",
            "Epoch #3 - Accuracy: 0.51\n",
            "Epoch #4 - Accuracy: 0.95\n",
            "Epoch #5 - Accuracy: 0.89\n",
            "Epoch #6 - Accuracy: 1.0\n",
            "Epoch #7 - Accuracy: 1.0\n",
            "Epoch #8 - Accuracy: 1.0\n",
            "Epoch #9 - Accuracy: 1.0\n",
            "Epoch #10 - Accuracy: 1.0\n",
            "Epoch #11 - Accuracy: 1.0\n",
            "Epoch #12 - Accuracy: 1.0\n",
            "Epoch #13 - Accuracy: 1.0\n",
            "Epoch #14 - Accuracy: 1.0\n",
            "Epoch #15 - Accuracy: 1.0\n",
            "Epoch #16 - Accuracy: 1.0\n",
            "Epoch #17 - Accuracy: 1.0\n",
            "Epoch #18 - Accuracy: 1.0\n",
            "Epoch #19 - Accuracy: 1.0\n",
            "Epoch #20 - Accuracy: 1.0\n",
            "Epoch #21 - Accuracy: 1.0\n",
            "Epoch #22 - Accuracy: 1.0\n",
            "Epoch #23 - Accuracy: 1.0\n",
            "Epoch #24 - Accuracy: 1.0\n",
            "Epoch #25 - Accuracy: 1.0\n",
            "Epoch #26 - Accuracy: 1.0\n",
            "Epoch #27 - Accuracy: 1.0\n",
            "Epoch #28 - Accuracy: 1.0\n",
            "Epoch #29 - Accuracy: 1.0\n",
            "Epoch #30 - Accuracy: 1.0\n",
            "Epoch #31 - Accuracy: 1.0\n"
          ]
        }
      ],
      "source": [
        "adaline = Adaline()\n",
        "adaline.fit(df2_X_scaled, df2_y, learning_rate=0.01, epochs=32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "598042ae",
      "metadata": {
        "id": "598042ae",
        "outputId": "a2b9f129-411e-4ea6-aa63-989cc3d84301"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch #0 - Accuracy: 0.5\n",
            "Epoch #1 - Accuracy: 0.5\n",
            "Epoch #2 - Accuracy: 0.5\n",
            "Epoch #3 - Accuracy: 0.5\n",
            "Epoch #4 - Accuracy: 0.5\n",
            "Epoch #5 - Accuracy: 0.5\n",
            "Epoch #6 - Accuracy: 0.5\n",
            "Epoch #7 - Accuracy: 0.5\n",
            "Epoch #8 - Accuracy: 0.53\n",
            "Epoch #9 - Accuracy: 0.5\n",
            "Epoch #10 - Accuracy: 0.58\n",
            "Epoch #11 - Accuracy: 0.5\n",
            "Epoch #12 - Accuracy: 0.6\n",
            "Epoch #13 - Accuracy: 0.54\n",
            "Epoch #14 - Accuracy: 0.64\n",
            "Epoch #15 - Accuracy: 0.58\n",
            "Epoch #16 - Accuracy: 0.67\n",
            "Epoch #17 - Accuracy: 0.66\n",
            "Epoch #18 - Accuracy: 0.76\n",
            "Epoch #19 - Accuracy: 0.7\n",
            "Epoch #20 - Accuracy: 0.78\n",
            "Epoch #21 - Accuracy: 0.73\n",
            "Epoch #22 - Accuracy: 0.79\n",
            "Epoch #23 - Accuracy: 0.75\n",
            "Epoch #24 - Accuracy: 0.82\n",
            "Epoch #25 - Accuracy: 0.78\n",
            "Epoch #26 - Accuracy: 0.85\n",
            "Epoch #27 - Accuracy: 0.83\n",
            "Epoch #28 - Accuracy: 0.89\n",
            "Epoch #29 - Accuracy: 0.86\n",
            "Epoch #30 - Accuracy: 0.9\n",
            "Epoch #31 - Accuracy: 0.86\n",
            "Epoch #32 - Accuracy: 0.92\n",
            "Epoch #33 - Accuracy: 0.87\n",
            "Epoch #34 - Accuracy: 0.94\n",
            "Epoch #35 - Accuracy: 0.88\n",
            "Epoch #36 - Accuracy: 0.95\n",
            "Epoch #37 - Accuracy: 0.89\n",
            "Epoch #38 - Accuracy: 0.95\n",
            "Epoch #39 - Accuracy: 0.91\n",
            "Epoch #40 - Accuracy: 0.95\n",
            "Epoch #41 - Accuracy: 0.91\n",
            "Epoch #42 - Accuracy: 0.95\n",
            "Epoch #43 - Accuracy: 0.92\n",
            "Epoch #44 - Accuracy: 0.94\n",
            "Epoch #45 - Accuracy: 0.93\n",
            "Epoch #46 - Accuracy: 0.94\n",
            "Epoch #47 - Accuracy: 0.93\n",
            "Epoch #48 - Accuracy: 0.94\n",
            "Epoch #49 - Accuracy: 0.93\n",
            "Epoch #50 - Accuracy: 0.94\n",
            "Epoch #51 - Accuracy: 0.95\n",
            "Epoch #52 - Accuracy: 0.94\n",
            "Epoch #53 - Accuracy: 0.95\n",
            "Epoch #54 - Accuracy: 0.96\n",
            "Epoch #55 - Accuracy: 0.96\n",
            "Epoch #56 - Accuracy: 0.96\n",
            "Epoch #57 - Accuracy: 0.96\n",
            "Epoch #58 - Accuracy: 0.96\n",
            "Epoch #59 - Accuracy: 0.96\n",
            "Epoch #60 - Accuracy: 0.96\n",
            "Epoch #61 - Accuracy: 0.97\n",
            "Epoch #62 - Accuracy: 0.96\n",
            "Epoch #63 - Accuracy: 0.97\n"
          ]
        }
      ],
      "source": [
        "adaline = Adaline()\n",
        "adaline.fit(df3_X_scaled, df3_y, learning_rate=0.01, epochs=64)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.8.15 ('college')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.15"
    },
    "vscode": {
      "interpreter": {
        "hash": "b25290d91e68666390a3f16911fef54d65a01c351d921450f79ed6c4a91d0756"
      }
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}